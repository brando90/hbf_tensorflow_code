I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:06:00.0
Total memory: 11.95GiB
Free memory: 11.84GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:06:00.0)
#!/usr/bin/env python
#!/usr/bin/python
>>> arg.restore =  False
['slurm-6617425_153.out', 'slurm-6617425_16.out', 'job_might_be_cancelled.txt', 'extract_results.py', 'slurm-6617425_8.out', 'slurm-6617426_60.out', 'slurm-6617426_66.out', 'slurm-6617426_54.out', 'f2D_plot_original_func.py', 'get_data_shuffled_coords.py', 'make_to_matlab.py', 'pickle_file', 'slurm-6617425_154.out', '1', 'f2D_krls.py', 'slurm-6617425_148.out', 'scripts_for_plotting', 'slurm-6617425_20.out', 'slurm-6617426_65.out', 'slurm-6617426_56.out', 'h_add_data_and_mesh.npz', 'slurm-6617425_7.out', 'data', 'before_vs_after_shuffle.py', 'slurm-6617425_155.out', 'data_om', '.swo', 'slurm-6617425_24.out', 'slurm-6617426_70.out', 'slurm-6617426_74.out', 'param_counter.py', 'hp_cpu', 'pca_mnist.py', 'slurm-6617425_157.out', 'slurm-6617425_156.out', 'binary_tree_with_f4d_data_float32.py', '.swn', 'slurm-6617426_12.out', 'slurm-6617425_13.out', 'test_print.py', 'om_f_8D_single_relu', 'slurm-6617426_73.out', 'slurm-6617425_27.out', 'slurm-6617426_53.out', 'slurm-6617425_26.out', 'delete.py', 'slurm-6617425_15.out', 'get_sense_of_data.py', 'om_f_4D_conv_2nd', 'slurm-6617426_62.out', 'slurm-6617426_69.out', 'batch_main.py', 'binary_tree_workspace', 'slurm-6617425_160.out', 'slurm-6617425_14.out', 'slurm-6617426_68.out', 'os_walk_test', 'slurm-6617426_72.out', 'parser_test.py', 'unit_test_large_hp.py', 'f2D_krls_random.py', 'generate_product_func.py', 'slurm-6617426_71.out', 'slurm-6617425_158.out', 'slurm-6617425_151.out', '__pycache__', 'slurm-6617426_57.out', 'plot_graphs.py', 'slurm-6617425_4.out', 'h_gabor_data_and_mesh.npz', 'slurm-6617426_52.out', 'slurm-6617426_58.out', 'output.file', 'hp_gpu', 'slurm-6617425_21.out', 'slurm-6617425_167.out', 'my_tf_proj.egg-info', 'generate_f8d.py', 'om_f_4D_conv_2nd_noise_3_0_25std', 'slurm-6617425_10.out', 'generate_2D_data.py', 'slurm-6617425_2.out', 'slurm-6617425_3.out', 'slurm-6617425_9.out', 'slurm-6617425_1.out', 'binary_tree_with_f4d_data.py', 'extract_results_matplotlib.py', '.swp', 'slurm-6617425_162.out', 'binary_tree_with_f4d_data_hbf_lib_maker.py', 'slurm-6617425_22.out', 'slurm-6617425_152.out', 'slurm-6617425_18.out', 'generate_f4d.py', 'f2D_recursive_krls.py', 'om_f_4D_cos_x2_BT', 'slurm-6617425_17.out', 'slurm-6617425_6.out', 'slurm-6617426_63.out', 'slurm-6617425_23.out', 'slurm-6617425_161.out', 'krls_plot_errrors_script.py', 'slurm-6617426_64.out', 'slurm-6617425_19.out', 'local_config.py', 'krls_collect_data.py', 'get_arguments.py', 'krls.py', 'generate_general_D.py', 'slurm-6617425_149.out', 'slurm-6617425_12.out', 'slurm-6617426_67.out', 'slurm-6617426_59.out', 'slurm-6617425_28.out', 'slurm-6617425_25.out', 'slurm-6617426_61.out', 'old_main.py', 'slurm-6617425_5.out', 'slurm-6617425_159.out', 'slurm-6617425_150.out', 'get_new_data_set_with_noise.py', 'get_sense_norm.py', 'slurm-6617426_55.out', 'slurm-6617425_11.out']
(N_train,D) = (60000,8) 
 (N_test,D_out) = (60000,1) 
arg.beta1 0.99
arg.beta2 0.999
step 0, train error: 0.535808 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 50, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 100, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 150, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 200, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 250, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 300, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 350, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 400, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 450, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 500, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 550, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 600, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 650, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 700, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 750, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 800, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 850, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 900, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 950, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1000, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1050, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1100, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1150, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1200, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1250, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1300, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1350, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1400, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1450, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1500, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1550, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1600, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1650, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1700, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1750, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1800, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1850, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1900, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 1950, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2000, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2050, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2100, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2150, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2200, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2250, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2300, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2350, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2400, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2450, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2500, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2550, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2600, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2650, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2700, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2750, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2800, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2850, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
step 2900, train error: 0.0973328 | batch_size(step.eval(),arg.batch_size): 14000,14000 log_learning_rate: -0.9435297931843312 
Traceback (most recent call last):
  File "/home/slurm/slurmd/job6627158/slurm_script", line 572, in <module>
    main_hp.main_hp(arg)
  File "/om/user/brando90/home_simulation_research/hbf_tensorflow_code/my_tf_proj/my_tf_pkg/main_hp.py", line 325, in main_hp
    saver.save(sess=sess,save_path=arg.path_to_ckpt+arg.hp_folder_for_ckpt+arg.prefix_ckpt)
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/training/saver.py", line 1335, in save
    self.export_meta_graph(meta_graph_filename)
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/training/saver.py", line 1368, in export_meta_graph
    clear_devices=clear_devices)
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/training/saver.py", line 1590, in export_meta_graph
    **kwargs)
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/meta_graph.py", line 651, in export_scoped_meta_graph
    as_text=as_text)
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/training/training_util.py", line 148, in write_graph
    file_io.atomic_write_string_to_file(path, graph_def.SerializeToString())
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py", line 350, in atomic_write_string_to_file
    write_string_to_file(temp_pathname, contents)
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py", line 249, in write_string_to_file
    f.write(file_content)
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py", line 90, in write
    self._prewrite_check()
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/lib/io/file_io.py", line 82, in _prewrite_check
    compat.as_bytes(self.__name), compat.as_bytes(self.__mode), status)
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/contextlib.py", line 66, in __exit__
    next(self.gen)
  File "/home/brando90/.conda/envs/tf_gpu/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: ../../all_ckpts/om_f_8D_product_continuous/task_Mar_2_BT_8D_Adam_xavier_relu_N60000_original_setup/job_mdl_folder_BT_8D_units2_Adam/hp_stid_60/mdl_ckpt.meta.tmp1899d738203e47568812222bdf7c0689
