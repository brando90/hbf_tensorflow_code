Processing /home_simulation_research/hbf_tensorflow_code/my_tf_proj
Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from my-tf-proj==0.1.0)
Requirement already satisfied: namespaces in /usr/local/lib/python3.5/dist-packages (from my-tf-proj==0.1.0)
Requirement already satisfied: pdb in /usr/local/lib/python3.5/dist-packages (from my-tf-proj==0.1.0)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.5/dist-packages (from my-tf-proj==0.1.0)
Requirement already satisfied: scipy in /usr/local/lib/python3.5/dist-packages (from my-tf-proj==0.1.0)
Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from namespaces->my-tf-proj==0.1.0)
Requirement already satisfied: argparse in /usr/local/lib/python3.5/dist-packages (from pdb->my-tf-proj==0.1.0)
Requirement already satisfied: python-gnupg in /usr/local/lib/python3.5/dist-packages (from pdb->my-tf-proj==0.1.0)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from pdb->my-tf-proj==0.1.0)
Installing collected packages: my-tf-proj
  Running setup.py install for my-tf-proj: started
    Running setup.py install for my-tf-proj: finished with status 'done'
Successfully installed my-tf-proj-0.1.0
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
#!/usr/bin/env python
#!/usr/bin/python
===> os.listdir(.):  ['.profile', '.bashrc', '.config', '.cache', '.bazelrc', '.jupyter']
os.getcwd():  /root
os.path.dirname(os.path.abspath(__file__)):  /home_simulation_research/hbf_tensorflow_code/tf_experiments_scripts
=======> path_to_task_exp /home_simulation_research/all_ckpts/om_f_8D_product_continuous/task_Mar_3_NN_8D_Adam_xavier_relu_N60000_original_setup_dgx1/job_mdl_folder_NN_8D_units14_Adam/
>>>some chekpoint exists
>>path_to_folder_with_hps_jobs:  /home_simulation_research/all_ckpts/om_f_8D_product_continuous/task_Mar_3_NN_8D_Adam_xavier_relu_N60000_original_setup_dgx1/job_mdl_folder_NN_8D_units14_Adam/
dirnames:  ['hp_stid_12']
largest_stid:  12
>>>found tf ckpt
>>>arg.save_path_to_ckpt2restore /home_simulation_research/all_ckpts/om_f_8D_product_continuous/task_Mar_3_NN_8D_Adam_xavier_relu_N60000_original_setup_dgx1/job_mdl_folder_NN_8D_units14_Adam/hp_stid_12/mdl_ckpt


--> stid:  12
/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:06:00.0
Total memory: 15.93GiB
Free memory: 392.25MiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0)
<built-in function print>
>>> arg.restore =  True
===> os.listdir(.):  ['.profile', '.bashrc', '.config', '.cache', '.bazelrc', '.jupyter']
os.getcwd():  /root
os.path.dirname(os.path.abspath(__file__)):  /usr/local/lib/python3.5/dist-packages/my_tf_pkg
(N_train,D) = (60000,8) 
 (N_test,D_out) = (60000,1) 
l  2
+++> std mu for inits_C:  [0, 1.9330765886949464]
arg.beta1 0.99
arg.beta2 0.999
Process Process-1:
Traceback (most recent call last):
  File "/usr/lib/python3.5/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/usr/lib/python3.5/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.5/dist-packages/my_tf_pkg/main_hp.py", line 296, in main_hp
    arg = restore_hps(arg)
  File "/usr/local/lib/python3.5/dist-packages/my_tf_pkg/main_hp.py", line 347, in restore_hps
    with open(arg.path_to_hp+arg.json_hp_filename, 'r') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home_simulation_research/simulation_results_scripts/om_f_8D_product_continuous/task_Mar_3_NN_8D_Adam_xavier_relu_N60000_original_setup_dgx1/job_mdl_folder_NN_8D_units14_Adam/json_hp_stid12'
--> Done!!! with stid:  12


--> stid:  13
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0000:06:00.0
Total memory: 15.93GiB
Free memory: 392.25MiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:06:00.0)
<built-in function print>
>>> arg.restore =  False
===> os.listdir(.):  ['.profile', '.bashrc', '.nv', '.config', '.cache', '.bazelrc', '.jupyter']
os.getcwd():  /root
os.path.dirname(os.path.abspath(__file__)):  /usr/local/lib/python3.5/dist-packages/my_tf_pkg
(N_train,D) = (60000,8) 
 (N_test,D_out) = (60000,1) 
l  2
+++> std mu for inits_C:  [0, 1.9330765886949464]
arg.beta1 0.99
arg.beta2 0.999
step 0, train error: 21.9191 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 50, train error: 10.3571 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 100, train error: 5.02868 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 150, train error: 2.97784 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 200, train error: 2.0051 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 250, train error: 1.38048 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 300, train error: 0.961508 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 350, train error: 0.775983 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 400, train error: 0.679187 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 450, train error: 0.532265 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 500, train error: 0.418386 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 550, train error: 0.377388 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 600, train error: 0.358814 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 650, train error: 0.330091 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 700, train error: 0.30334 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 750, train error: 0.284853 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 800, train error: 0.268034 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 850, train error: 0.253007 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 900, train error: 0.241022 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 950, train error: 0.230166 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1000, train error: 0.220215 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1050, train error: 0.211213 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1100, train error: 0.202793 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1150, train error: 0.195004 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1200, train error: 0.187842 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1250, train error: 0.181381 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1300, train error: 0.175498 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1350, train error: 0.17007 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1400, train error: 0.165062 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1450, train error: 0.160291 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1500, train error: 0.155886 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1550, train error: 0.151723 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1600, train error: 0.147798 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1650, train error: 0.144129 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1700, train error: 0.140714 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1750, train error: 0.137535 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1800, train error: 0.134487 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1850, train error: 0.131628 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1900, train error: 0.128983 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 1950, train error: 0.126501 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2000, train error: 0.124132 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2050, train error: 0.122002 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2100, train error: 0.120022 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2150, train error: 0.118118 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2200, train error: 0.116418 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2250, train error: 0.11489 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2300, train error: 0.113373 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2350, train error: 0.111996 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2400, train error: 0.110812 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2450, train error: 0.10964 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2500, train error: 0.108623 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2550, train error: 0.107636 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2600, train error: 0.106761 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2650, train error: 0.105984 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2700, train error: 0.105299 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2750, train error: 0.104689 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2800, train error: 0.10418 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2850, train error: 0.1037 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2900, train error: 0.103228 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 2950, train error: 0.102901 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3000, train error: 0.10254 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3050, train error: 0.102339 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3100, train error: 0.102002 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3150, train error: 0.101766 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3200, train error: 0.1015 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3250, train error: 0.10136 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3300, train error: 0.10113 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3350, train error: 0.10096 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3400, train error: 0.100789 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3450, train error: 0.100637 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3500, train error: 0.100506 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3550, train error: 0.100322 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3600, train error: 0.100198 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3650, train error: 0.100043 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3700, train error: 0.0999468 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3750, train error: 0.0998279 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3800, train error: 0.0996891 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3850, train error: 0.0996034 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3900, train error: 0.0995009 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 3950, train error: 0.0993698 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4000, train error: 0.099329 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4050, train error: 0.0992136 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4100, train error: 0.0990996 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4150, train error: 0.0990893 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4200, train error: 0.0989435 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4250, train error: 0.0988663 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4300, train error: 0.0988262 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4350, train error: 0.0988313 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4400, train error: 0.0986502 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4450, train error: 0.0986871 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4500, train error: 0.0985615 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4550, train error: 0.0984833 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4600, train error: 0.0984053 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4650, train error: 0.0983805 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4700, train error: 0.0983211 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4750, train error: 0.0982022 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4800, train error: 0.0982199 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4850, train error: 0.0981296 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4900, train error: 0.0980815 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 4950, train error: 0.098066 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5000, train error: 0.0980464 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5050, train error: 0.0978983 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5100, train error: 0.097968 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5150, train error: 0.0977615 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5200, train error: 0.0977234 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5250, train error: 0.0977846 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5300, train error: 0.0977044 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5350, train error: 0.0976767 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5400, train error: 0.0976044 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5450, train error: 0.0975512 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5500, train error: 0.0975826 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5550, train error: 0.097554 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5600, train error: 0.0975388 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5650, train error: 0.0975086 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5700, train error: 0.097521 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5750, train error: 0.0975538 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5800, train error: 0.0974406 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5850, train error: 0.0974368 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5900, train error: 0.0975037 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 5950, train error: 0.0974511 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6000, train error: 0.0975042 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6050, train error: 0.0973357 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6100, train error: 0.0974072 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6150, train error: 0.0973353 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6200, train error: 0.0973051 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6250, train error: 0.097288 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6300, train error: 0.0973023 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6350, train error: 0.0972832 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6400, train error: 0.0972694 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6450, train error: 0.0972863 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6500, train error: 0.0973524 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6550, train error: 0.0973032 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6600, train error: 0.0972978 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6650, train error: 0.097235 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6700, train error: 0.0972391 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6750, train error: 0.0972277 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6800, train error: 0.0971755 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6850, train error: 0.097213 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6900, train error: 0.0971907 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 6950, train error: 0.0972365 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7000, train error: 0.0971557 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7050, train error: 0.0973822 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7100, train error: 0.0971645 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7150, train error: 0.0971444 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7200, train error: 0.0971342 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7250, train error: 0.0972365 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7300, train error: 0.0972003 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7350, train error: 0.0972196 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7400, train error: 0.0971593 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7450, train error: 0.097147 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7500, train error: 0.0971844 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7550, train error: 0.0972683 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7600, train error: 0.0972034 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7650, train error: 0.0970862 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7700, train error: 0.0973199 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7750, train error: 0.0971742 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7800, train error: 0.0971817 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7850, train error: 0.0972782 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7900, train error: 0.0972582 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 7950, train error: 0.0970821 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8000, train error: 0.0971388 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8050, train error: 0.0970848 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8100, train error: 0.0970202 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8150, train error: 0.097101 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8200, train error: 0.0971159 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8250, train error: 0.0971076 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8300, train error: 0.0972183 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8350, train error: 0.0970616 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8400, train error: 0.0971045 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8450, train error: 0.0970908 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8500, train error: 0.096947 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8550, train error: 0.096919 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8600, train error: 0.0969121 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8650, train error: 0.0967315 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8700, train error: 0.0966357 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8750, train error: 0.096623 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8800, train error: 0.0965746 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8850, train error: 0.0965781 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8900, train error: 0.0965225 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 8950, train error: 0.0964802 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9000, train error: 0.0964088 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9050, train error: 0.0964116 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9100, train error: 0.0964941 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9150, train error: 0.0964186 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9200, train error: 0.0965243 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9250, train error: 0.0963946 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9300, train error: 0.0964088 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9350, train error: 0.0964201 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9400, train error: 0.0965216 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9450, train error: 0.0964649 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9500, train error: 0.0964312 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9550, train error: 0.0964208 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 
step 9600, train error: 0.0962921 | batch_size(step.eval(),arg.batch_size): 14451,14451 log_learning_rate: -3.042604666723732 slurmstepd: error: *** STEP 15895.0 ON dgx1 CANCELLED AT 2017-03-10T19:53:26 ***
